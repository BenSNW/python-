# python

Python Codes

Keras version used in models: keras==1.1.0 | LSTM 0.2



<B> Python - Autoencoder MNIST:</B> is an autoencoder model for classification of images developed with Keras, for the MNIST dataset, with model Checkpoint as a callback to save weights.

<B>Python - Autoencoder for Text Classification: </B>is an autoencoder model for classification of text made with Keras, also with model Checkpoint.

<B>Python - Deep Learning with Lasagne:</B> is a deep neural network developed with Lasagne, where you can see values of weights in each layer, including bias.

<B>Python - Face Recognition:</B> is a model using OpenCV to detect faces.

<B>Python - Image Extraction from Twitter:</B> is a model that extracts pictures and their links from Twitter webpages, plotting with matplotlib.

<B>Python - Keras Convolutional Neural Network:</B> is a CNN developed to classify the MNIST dataset with an accuracy greater than 99%.

<B>Python - Keras Deep Regressor: </B>is a deep Neural Network for prediction of a continuous output made with Keras, learning rate scheduler according to derivative of error, random initial weights, with loss history.

<B>Python - Keras LSTM Network:</B> is a Recurrent Neural Network (LSTM) to predict and generate text.

<B>Python - Keras Multi Layer Perceptron: </B>is a MLP model, Neural Networks made with Keras with loss history, scheduled learning rate according to derivative of error for prediction and classification.

<B>Python - Machine Learning:</B> is a Principal Components Analysis followed by a Linear Regression.

<B>Python - NLP Doc2Vec:</B> is a Natural Language Processing model where I asked a Wikipedia webpage a question and 4 possible answers were semantically chosen from the tokenized and vectorized webpage, using KNN and cosine distance.

<B>Python - NLP Semantic Analysis:</B> is a Natural Language Processing model that classifies a given sentence according to semantic similarity to other sentences, using cosine distance.

<B>Python - NLP Word2Vec:</B> is a model developed from scratch to measure cosine similarity among words.

<B>Python - Reinforcement Learning:</B> is a model based on simple rules and Game Theory where agents attitude change according to payoff achieved. Can be adapted for tit-for-tat strategy, always cooperate, always defeat and other strategies. Rewards were placed in the payoff matrix.

<B>Python - Social Networks:</B> is a model that draws social networks configuration and connections.

<B>Python - Support Vector Machines:</B> is a Machine Learning model that classifies the Iris dataset with SVM and plots it.

<B>Python - Theano Deep Learning: </B> is a Neural Network with two hidden layers using Theano.

<B>Autoencoder </B> for Audio is a model where I compressed an audio file and used Autoencoder to reconstruct the audio file, for use in phoneme classification.

<B>Collaborative Filtering is a Recommender System </B>where the algorithm predicts a movie review based on genre of movie and similarity among people who watched the same movie.

<B>Convolutional NN Lasagne </B>is a Convolutional Neural Network model in Lasagne to solve the MNIST task.

<B>Ensembled Machine Learning </B>is a .py file where 7 Machine Learning algorithms are used in a classification task with 3 classes and all possible hyperparameters of each algorithm are adjusted. Iris dataset of scikit-learn.

<B>GAN Generative Adversarial</B> are models of Generative Adversarial Neural Networks.

<B>Hyperparameter Tuning RL</B> is a model where hyperparameters of Neural Networks are adjusted via Reinforcement Learning. According to a reward, hyperparameter tuning (environment) is changed through a policy (mechanization of knowledge) using the Boston Dataset. Hyperparameters tuned are: learning rate, epochs, decay, momentum, number of hidden layers and nodes and initial weights.

<B>Keras Regularization L2 is a Neural Network model </B>for regression made with Keras where a L2 regularization was applied to prevent overfitting.

<B>Lasagne Neural Nets Regression</B> is a Neural Network model based in Theano and Lasagne, that makes a linear regression with a continuous target variable and reaches 99.4% accuracy. It uses the DadosTeseLogit.csv sample file.

<B>Lasagne Neural Nets </B>+ Weights is a Neural Network model based in Theano and Lasagne, where is possible to visualize weights between X1 and X2 to hidden layer. Can also be adapted to visualize weights between hidden layer and output. It uses the DadosTeseLogit.csv sample file.

<B>Multinomial Regression </B>is a regression model where target variable has 3 classes.

<B>Neural Networks for Regression</B> shows multiple solutions for a regression problem, solved with sklearn, Keras, Theano and Lasagne. It uses the Boston dataset sample file from sklearn and reaches more than 98% accuracy.

<B>NLP + Naive Bayes Classifier</B> is a model where movie reviews were labeled as positive and negative and the algorithm then classifies a totally new set of reviews using Logistic Regression, Decision Trees and Naive Bayes, reaching an accuracy of 92%.

<B>NLP Anger Analysis is a Doc2Vec</B> model associated with Word2Vec model to analyze level of anger using synonyms in consumer complaints of a U.S. retailer in Facebook posts.

<B>NLP Consumer Complaint </B>is a model where Facebook posts of a U.S. computer retailer were scraped, tokenized, lemmatized and applied Word2Vec. After that, t-SNE and Latent Dirichlet Allocation were developed in order to classify the arguments and weights of each keyword used by a consumer in his complaint. The code also analyzes frequency of words in 100 posts.

<B>NLP Convolutional Neural Network </B>is a Convolutional Neural Network for Text in order to classify movie reviews.

<B>NLP Doc2Vec </B> is a Natural Language Procesing file where cosine similarity among phrases is measured through Doc2Vec.

<B>NLP Document Classification </B>is a code for Document Classification according to Latent Dirichlet Allocation.

<B>NLP Facebook Analysis </B> analyzes Facebook posts regarding Word Frequency and Topic Modelling using LDA.

<B>NLP Facebook Scrap </B>is a Python code for scraping data from Facebook.

<B>NLP - Latent Dirichlet Allocation </B>is a Natural Language Processing model where a Wikipedia page on Statistical Inference is classified regarding topics, using Latent Dirichlet Allocation with Gensim, NLTK, t-SNE and K-Means.

<B>NLP Probabilistic ANN </B>is a Natural Language Processing model where sentences are vectorized by Gensim and a probabilistic Neural Network model is deveoped using Gensim, for sentiment analysis.

<B>NLP Semantic Doc2Vec + Neural Network</B> is a model where positive and negative movie reviews were extracted and semantically classified with NLTK and BeautifulSoup, then labeled as positive or negative. Text was then used as an input for the Neural Network model training. After training, new sentences are entered in the Keras Neural Network model and then classified. It uses the zip file.

<B>NLP Sentiment Positive </B>is a model that identifies website content as positive, neutral or negative using BeautifulSoup and NLTK libraries, plotting the results.

<B>NLP Twitter Analysis ID </B># is a model that extracts posts from Twitter based in ID of user or Hashtag.

<B>NLP Twitter Scrap</B> is a model that scraps Twitter data and shows the cleaned text as output.

<B>NLP Twitter Streaming </B>is a model of analysis of real-time data from Twitter (under development).

<B>NLP Twitter Streaming Mood</B> is a model where the evolution of mood Twitter posts is measured during a period of time.

<B>NLP Wikipedia Summarization</B> is a Python code that summarizes any given page in a few sentences.

<B>NLP Word Frequency </B>is a model that calculates the frequency of nouns, verbs, words in Facebook posts.

<B>Probabilistic Neural Network</B> is a Probabilistic Neural Network for Time Series Prediction.

<B>REAL-TIME Twitter Analysis</B> is a model where Twitter streaming is extracted, words and sentences tokenized, word embeddings were created, topic modeling was made and classified using K-Means. Then, NLTK SentimentAnalyzer was used to classify each sentence of the streaming into positive, neutral or negative. Accumulated sum was used to generate the plot and the code loops each 1 second, collecting new tweets.

<B>RESNET-2 </B>is a Deep Residual Neural Network.

<B>ROC Curve Multiclass </B>is a .py file where Naive Bayes was used to solve the IRIS Dataset task and ROC curve of different classes are plotted.

<B>SQUEEZENET</B> is a simplified version of the AlexNet.

<B>Stacked Machine Learning </B>is a .py notebook where t-SNE, Principal Components Analysis and Factor Analysis were applied to reduce dimensionality of data. Classification performances were measured after applying K-Means.

<B>Support Vector Regression </B>is a SVM model for non linear regression in an artificial dataset.

<B>Text-to-Speech </B>is a .py file where Python speaks any given text and saves it as an audio .wav file.

<B>Time Series ARIMA </B>is a ARIMA model to forecast time series, with an error margin of 0.2%.

<B>Time Series Prediction with Neural Networks </B> - Keras is a Neural Network model to forecast time series, using Keras with an adaptive learning rate depending upon derivative of loss.

<B>Variational Autoencoder </B>is a VAE made with Keras.

<B>Web Crawler </B>is a code that scraps data from different URLs of a hotel website.

<B>t-SNE Dimensionality Reduction </B> is a t-SNE model for dimensionality reduction which is compared to Principal Components Analysis regarding its discriminatory power.

<B>t-SNE PCA + Neural Networks </B> is a model that compares performance or Neural Networks made after t-SNE, PCA and K-Means.

<B>t-SNE PCA LDA embeddings </B> is a model where t-SNE, Principal Components Analysis, Linear Discriminant Analysis and Random Forest embeddings are compared in a task to classify clusters of similar digits.






